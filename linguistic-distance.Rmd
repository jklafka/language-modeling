---
title: "linguistic_distance"
author: "Josef Klafka and Daniel Yurovsky"
date: "12/2/2019"
output: html_document
---

```{r setup, include=FALSE}
require(tidyverse)
require(here)
require(janitor)
require(missMDA)
require(tidyboot)
require(viridis)
require(stringdist)
require(lsa)

knitr::opts_chunk$set(echo = TRUE)
```

```{r get data and preprocess}
iso_to_language <- read_csv(here("Data/wiki/codes.csv")) %>%
  select(language, iso) %>%
  group_by(language) %>%
  slice(1) %>% 
  ungroup()

asjp_forms <- read_csv(here("Data/asjp_dataset/forms.csv"))
asjp_langs <- read_csv(here("Data/asjp_dataset/languages.csv"))
lang_forms <- asjp_forms %>% 
  select(Language_ID, Parameter_ID, Form) %>% 
  left_join(asjp_langs %>% select(ID, ISO639P3code), by = c("Language_ID" = "ID")) %>%
  left_join(iso_to_language, by = c("ISO639P3code" = "iso")) %>%
  filter(complete.cases(.)) %>% 
  select(language, Parameter_ID, Form) %>%
  group_by(language, Parameter_ID) %>% ## taking off one at random for each language - fix
  slice(1) %>%
  ungroup() 

wals_features <- read_csv(here("Data/Paper/wals_features.csv")) %>%
  pivot_longer(-language, names_to = "feature", values_to = "value")

langs <- iso_to_language %>% pull(language) ## change this

langs_pairwise <- expand.grid(language1 = langs,
                           language2 = langs) %>%
  filter(language1 != language2)
```

```{r make wals distance space}
wals_distance <- function(language1, language2) {
  wals_features %>% 
    filter(language == language1) %>%
    left_join(wals_features %>% filter(language == language2), by = "feature") %>% 
    filter(complete.cases(.)) %>% 
    mutate(wals_dist = ifelse(value.x == value.y, 1, 0)) %>%
    group_by(language.x, language.y) %>% 
    summarise(wals_dist = sum(wals_dist)) %>% 
    rename(language1 = language.x, language2 = language.y) %>% 
    ungroup()
}

wals_space <- map_dfr(1:nrow(langs_pairwise), ~wals_distance(langs_pairwise[.x,"language1"],
                                          langs_pairwise[.x,"language2"])) 
```

```{r make swadesh distance space}
asjp_distance <- function(language1, language2) {
  lang_forms %>% 
    filter(language == language1) %>%
    left_join(lang_forms %>% filter(language == language2), by = "Parameter_ID") %>% 
    filter(complete.cases(.)) %>% 
    mutate(ldn = stringdist(Form.x, Form.y) / max(str_length(c(Form.x, Form.y)))) %>%
    group_by(language.x, language.y) %>% 
    summarise(ldn = mean(ldn)) %>% 
    rename(language1 = language.x, language2 = language.y) %>% 
    ungroup()
}

swadesh_space <- map_dfr(1:nrow(langs_pairwise), ~asjp_distance(langs_pairwise[.x,"language1"],
                                          langs_pairwise[.x,"language2"])) 
```

Download and unzip the WALS data file from "https://wals.info/download" (the file is called wals_language.csv.zip) to get the originals for this data processing pipeline. Codes are created from the language_dict.json file in the top-level directory of the repository, filled out manually from here: "https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Languages/List_of_ISO_639-3_language_codes_(2019)"
```{r get WALS features, echo = F, include = F}
# get all of the features for each language
langs <- read_csv(here("Data/wiki/wals_dataset/languages.csv")) %>% 
  select(ID, ISO639P3code) %>%
  rename(iso = ISO639P3code)

values <- read_csv(here("Data/wiki/wals_dataset/values.csv")) %>%
  select(Language_ID, Parameter_ID, Value) %>% 
  pivot_wider(names_from = Parameter_ID, values_from = Value) %>% 
  left_join(langs, by = c("Language_ID" = "ID")) %>%
  clean_names()

# ## imputation
# imputed_wals <- values %>%
#   column_to_rownames("language_id") %>%
#   filter_all(any_vars(!is.na(.))) %>% # each language and each feature has at least one value
#   MIMCA(ncp = 50, threshold = 1e-2, maxiter = 500)

wiki <- read_csv(here("Data/Wikipedia/codes.csv"))
slopes <- read_csv(here("Data/Paper/relative_ngrams.csv"))

features <- values %>% 
  left_join(wiki, by = "iso") %>%
  filter(!is.na(language))

# features %>% 
#   column_to_rownames("language_id") %>%
#   filter_all(any_vars(!is.na(.))) %>% # each language and each feature has at least one value
#   MIMCA(ncp = 20, threshold = 1e-2, maxiter = 1000)
```

Does word order covary with trigram information curve shape? It seems like yes, although the aggregated curves you get for each language family are difficult to understand. 
```{r shape-feature covariance}
boot_slopes <- features %>% 
  inner_join(slopes %>% filter(gram == "Unigram"), by = "language") %>% 
  filter(!is.na(x81a)) %>% 
  select(language, x81a, slope1:slope5) %>% 
  mutate(slope0 = runif(1, 0.9, 1.1)) %>% 
  mutate(slope1 = slope1 + slope0) %>% 
  mutate(slope2 = slope2 + slope1) %>% 
  mutate(slope3 = slope3 + slope2) %>% 
  mutate(slope4 = slope4 + slope3) %>% 
  mutate(slope5 = slope5 + slope4) %>% 
  pivot_longer(cols = slope1:slope0, names_to = "slope", values_to = "value") %>%
  group_by(x81a, slope) %>%
  tidyboot_mean(column = value) %>%
  ungroup()

boot_slopes %>% 
  mutate(slope = str_extract(slope, "\\d"), # turn slope into integer
         slope = as.integer(slope) + 1) %>%
    ggplot(aes(x = slope, y = empirical_stat, group = x81a, color = x81a)) + 
    geom_point() + 
    # geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.25) + 
    geom_line() + 
    xlab("Word position") + 
    ylab("Average Information") + 
    theme(axis.text.x = element_blank()) + 
    scale_color_viridis(discrete = T, option = "C")
```

Are information curve shapes consistent within language families? 
language.csv is from "https://wals.info/download", in wals_language.csv.zip. It's the only file in the zip. 
```{r language family}
slopes <- read_csv(here("Data/Paper/relative_ngrams.csv"))
families <- read_csv(here("Data/Wikipedia/wals_dataset/language.csv"))

## match up language curves with their language families
family_slopes <- features %>% 
  select(language, iso) %>% 
  inner_join(slopes) %>% 
  inner_join(families %>% select(iso_code, family), by = c("iso" = "iso_code")) %>% 
  distinct() ## deduplicate--WALS has some duplicate entries but doesn't affect families

## construct sample curves and bootstrap
family_bootstraps <- family_slopes %>% 
  select(-iso) %>% 
  mutate(slope0 = 5) %>% 
  mutate(slope1 = slope1 + slope0) %>% 
  mutate(slope2 = slope2 + slope1) %>% 
  mutate(slope3 = slope3 + slope2) %>% 
  mutate(slope4 = slope4 + slope3) %>% 
  mutate(slope5 = slope5 + slope4) %>% 
  pivot_longer(cols = c(slope1:slope5, slope0), names_to = "slope", values_to = "value") %>%
  group_by(family, gram, slope) %>%
  tidyboot_mean(column = value) %>%
  ungroup()

## plotting the sample curves
family_bootstraps %>% 
  mutate(slope = str_extract(slope, "\\d"), # turn slope into integer
         slope = as.integer(slope) + 1) %>%
  filter(gram == "Trigram") %>% 
  ggplot(aes(x = slope, y = empirical_stat, group = gram, color = gram)) + 
    geom_point() + 
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.25) +
    geom_line() + 
    facet_wrap(~family) + 
    xlab("Word position") + 
    ylab("Average Information") + 
    theme(axis.text.x = element_blank()) + 
    scale_color_manual(values = c("#8b0000"))

# ## why do the unigram curves look so flat in comparison?
# family_slopes %>% 
#   filter(gram == "Unigram") %>% 
#   group_by(family)
```
